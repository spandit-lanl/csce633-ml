

Hyperparameter tuning for Linear Regression

[LR: 0.0100, max_iter:     500 lambda: 0.0000] --> RMSE: 76.9957422660465
[LR: 0.0100, max_iter:     500 lambda: 0.0000] --> RMSE: 76.99597629109292
[LR: 0.0100, max_iter:     500 lambda: 0.0001] --> RMSE: 76.9959701049718
[LR: 0.0100, max_iter:     500 lambda: 0.0001] --> RMSE: 76.9962052924791
[LR: 0.0100, max_iter:     500 lambda: 0.0001] --> RMSE: 76.99607171213177
[LR: 0.0100, max_iter:     500 lambda: 0.0002] --> RMSE: 76.9969671847372
[LR: 0.0100, max_iter:     500 lambda: 0.0004] --> RMSE: 76.9977304927219
[LR: 0.0200, max_iter:     500 lambda: 0.0000] --> RMSE: 76.75332055704119
[LR: 0.0200, max_iter:     500 lambda: 0.0000] --> RMSE: 76.75347975076232
[LR: 0.0200, max_iter:     500 lambda: 0.0001] --> RMSE: 76.75379754163265
[LR: 0.0200, max_iter:     500 lambda: 0.0001] --> RMSE: 76.75407713723916
[LR: 0.0200, max_iter:     500 lambda: 0.0001] --> RMSE: 76.75405303078055
[LR: 0.0200, max_iter:     500 lambda: 0.0002] --> RMSE: 76.7546671687079
[LR: 0.0200, max_iter:     500 lambda: 0.0004] --> RMSE: 76.75580630147402
[LR: 0.0200, max_iter:     500 lambda: 0.0008] --> RMSE: 76.75830973057091
[LR: 0.0200, max_iter:     500 lambda: 0.0010] --> RMSE: 76.75965159572728
[LR: 0.0200, max_iter:     500 lambda: 0.0020] --> RMSE: 76.76603330875041
[LR: 0.0200, max_iter:     500 lambda: 0.0050] --> RMSE: 76.78606752610114
[LR: 0.0200, max_iter:     500 lambda: 0.0080] --> RMSE: 76.80708115219288
[LR: 0.0200, max_iter:     500 lambda: 0.0100] --> RMSE: 76.82169748509536
[LR: 0.0200, max_iter:     500 lambda: 0.0200] --> RMSE: 76.89981123540122
[LR: 0.0400, max_iter:     500 lambda: 0.0000] --> RMSE: 76.64267691045309
[LR: 0.0400, max_iter:     500 lambda: 0.0000] --> RMSE: 76.6428518390961
[LR: 0.0400, max_iter:     500 lambda: 0.0001] --> RMSE: 76.64293292311132
[LR: 0.0400, max_iter:     500 lambda: 0.0001] --> RMSE: 76.64309794783594
[LR: 0.0400, max_iter:     500 lambda: 0.0001] --> RMSE: 76.64319437591485
[LR: 0.0400, max_iter:     500 lambda: 0.0002] --> RMSE: 76.64378901459537
[LR: 0.0400, max_iter:     500 lambda: 0.0004] --> RMSE: 76.64499585277551
[LR: 0.0400, max_iter:     500 lambda: 0.0008] --> RMSE: 76.6475515819646
[LR: 0.0400, max_iter:     500 lambda: 0.0010] --> RMSE: 76.64877313991457
[LR: 0.0400, max_iter:     500 lambda: 0.0020] --> RMSE: 76.65520505251226
[LR: 0.0400, max_iter:     500 lambda: 0.0050] --> RMSE: 76.67598991138372
[LR: 0.0400, max_iter:     500 lambda: 0.0080] --> RMSE: 76.69865929922966
[LR: 0.0400, max_iter:     500 lambda: 0.0100] --> RMSE: 76.71472402497149
[LR: 0.0400, max_iter:     500 lambda: 0.0200] --> RMSE: 76.80408117587332
[LR: 0.0600, max_iter:     500 lambda: 0.0000] --> RMSE: 76.61269666295053
[LR: 0.0600, max_iter:     500 lambda: 0.0000] --> RMSE: 76.61281605594714
[LR: 0.0600, max_iter:     500 lambda: 0.0001] --> RMSE: 76.61288536590446
[LR: 0.0600, max_iter:     500 lambda: 0.0001] --> RMSE: 76.61300577755571
[LR: 0.0600, max_iter:     500 lambda: 0.0001] --> RMSE: 76.61312839841247
[LR: 0.0600, max_iter:     500 lambda: 0.0002] --> RMSE: 76.61371837090154
[LR: 0.0600, max_iter:     500 lambda: 0.0004] --> RMSE: 76.61489124798375
[LR: 0.0600, max_iter:     500 lambda: 0.0008] --> RMSE: 76.61725721110325
[LR: 0.0600, max_iter:     500 lambda: 0.0010] --> RMSE: 76.61845772086141
[LR: 0.0600, max_iter:     500 lambda: 0.0020] --> RMSE: 76.6247215576162
[LR: 0.0600, max_iter:     500 lambda: 0.0050] --> RMSE: 76.64571824957274
[LR: 0.0600, max_iter:     500 lambda: 0.0080] --> RMSE: 76.66945679530888
[LR: 0.0600, max_iter:     500 lambda: 0.0100] --> RMSE: 76.68649639185925
[LR: 0.0600, max_iter:     500 lambda: 0.0200] --> RMSE: 76.78197043944279
[LR: 0.0800, max_iter:     500 lambda: 0.0000] --> RMSE: 76.60036171934442
[LR: 0.0800, max_iter:     500 lambda: 0.0000] --> RMSE: 76.60050159241703
[LR: 0.0800, max_iter:     500 lambda: 0.0001] --> RMSE: 76.6006226062008
[LR: 0.0800, max_iter:     500 lambda: 0.0001] --> RMSE: 76.6006857830946
[LR: 0.0800, max_iter:     500 lambda: 0.0001] --> RMSE: 76.6008120449209
[LR: 0.0800, max_iter:     500 lambda: 0.0002] --> RMSE: 76.60138407494405
[LR: 0.0800, max_iter:     500 lambda: 0.0004] --> RMSE: 76.60247598385244
[LR: 0.0800, max_iter:     500 lambda: 0.0008] --> RMSE: 76.60480537827642
[LR: 0.0800, max_iter:     500 lambda: 0.0010] --> RMSE: 76.60598378316045
[LR: 0.0800, max_iter:     500 lambda: 0.0020] --> RMSE: 76.61223497230806
[LR: 0.0800, max_iter:     500 lambda: 0.0050] --> RMSE: 76.63356736096367
[LR: 0.0800, max_iter:     500 lambda: 0.0080] --> RMSE: 76.65811762127673
[LR: 0.0800, max_iter:     500 lambda: 0.0100] --> RMSE: 76.67584867524683
[LR: 0.0800, max_iter:     500 lambda: 0.0200] --> RMSE: 76.77504998093457
[LR: 0.1000, max_iter:     500 lambda: 0.0000] --> RMSE: 76.59372521830429
[LR: 0.1000, max_iter:     500 lambda: 0.0000] --> RMSE: 76.59383094050118
[LR: 0.1000, max_iter:     500 lambda: 0.0001] --> RMSE: 76.59393957198911
[LR: 0.1000, max_iter:     500 lambda: 0.0001] --> RMSE: 76.59404986322983
[LR: 0.1000, max_iter:     500 lambda: 0.0001] --> RMSE: 76.59415966013788
[LR: 0.1000, max_iter:     500 lambda: 0.0002] --> RMSE: 76.59469642135389
[LR: 0.1000, max_iter:     500 lambda: 0.0004] --> RMSE: 76.59581138862114
[LR: 0.1000, max_iter:     500 lambda: 0.0008] --> RMSE: 76.59811261467335
[LR: 0.1000, max_iter:     500 lambda: 0.0010] --> RMSE: 76.59929549702402
[LR: 0.1000, max_iter:     500 lambda: 0.0020] --> RMSE: 76.60556521141154
[LR: 0.1000, max_iter:     500 lambda: 0.0050] --> RMSE: 76.62734504819038
[LR: 0.1000, max_iter:     500 lambda: 0.0080] --> RMSE: 76.65260121764001
[LR: 0.1000, max_iter:     500 lambda: 0.0100] --> RMSE: 76.67086410540847
[LR: 0.1000, max_iter:     500 lambda: 0.0200] --> RMSE: 76.77240889418964

[LR: 0.0060, max_iter:    1000 lambda: 0.0000] --> RMSE: 76.91393434370927
[LR: 0.0060, max_iter:    1000 lambda: 0.0000] --> RMSE: 76.9140106060856
[LR: 0.0060, max_iter:    1000 lambda: 0.0001] --> RMSE: 76.91422864164997
[LR: 0.0060, max_iter:    1000 lambda: 0.0001] --> RMSE: 76.91429076176391
[LR: 0.0060, max_iter:    1000 lambda: 0.0001] --> RMSE: 76.91414144259636
[LR: 0.0060, max_iter:    1000 lambda: 0.0002] --> RMSE: 76.91515869886965
[LR: 0.0060, max_iter:    1000 lambda: 0.0004] --> RMSE: 76.91611124837769
[LR: 0.0060, max_iter:    1000 lambda: 0.0008] --> RMSE: 76.9183286266448
[LR: 0.0060, max_iter:    1000 lambda: 0.0010] --> RMSE: 76.91957842067123
[LR: 0.0060, max_iter:    1000 lambda: 0.0020] --> RMSE: 76.92557492774642
[LR: 0.0060, max_iter:    1000 lambda: 0.0050] --> RMSE: 76.94370088365937
[LR: 0.0060, max_iter:    1000 lambda: 0.0080] --> RMSE: 76.96288153577233
[LR: 0.0060, max_iter:    1000 lambda: 0.0100] --> RMSE: 76.9759707284309
[LR: 0.0080, max_iter:    1000 lambda: 0.0000] --> RMSE: 76.81255318567092
[LR: 0.0080, max_iter:    1000 lambda: 0.0000] --> RMSE: 76.81262085456801
[LR: 0.0080, max_iter:    1000 lambda: 0.0001] --> RMSE: 76.81275589318156
[LR: 0.0080, max_iter:    1000 lambda: 0.0001] --> RMSE: 76.81309190235447
[LR: 0.0080, max_iter:    1000 lambda: 0.0001] --> RMSE: 76.81298230869366
[LR: 0.0080, max_iter:    1000 lambda: 0.0002] --> RMSE: 76.81360279806889
[LR: 0.0080, max_iter:    1000 lambda: 0.0004] --> RMSE: 76.81494586015492
[LR: 0.0080, max_iter:    1000 lambda: 0.0008] --> RMSE: 76.81742181231094
[LR: 0.0080, max_iter:    1000 lambda: 0.0010] --> RMSE: 76.81874926695926
[LR: 0.0080, max_iter:    1000 lambda: 0.0020] --> RMSE: 76.82489447698879
[LR: 0.0080, max_iter:    1000 lambda: 0.0050] --> RMSE: 76.8445291381
[LR: 0.0080, max_iter:    1000 lambda: 0.0080] --> RMSE: 76.86472631520643
[LR: 0.0080, max_iter:    1000 lambda: 0.0100] --> RMSE: 76.87855777549463
[LR: 0.0080, max_iter:    1000 lambda: 0.0200] --> RMSE: 76.95328927515494
[LR: 0.0100, max_iter:    1000 lambda: 0.0000] --> RMSE: 76.75361196174318
[LR: 0.0100, max_iter:    1000 lambda: 0.0000] --> RMSE: 76.75381198820205
[LR: 0.0100, max_iter:    1000 lambda: 0.0001] --> RMSE: 76.75378266060477
[LR: 0.0100, max_iter:    1000 lambda: 0.0001] --> RMSE: 76.75402647466984
[LR: 0.0100, max_iter:    1000 lambda: 0.0001] --> RMSE: 76.75403254128592
[LR: 0.0100, max_iter:    1000 lambda: 0.0002] --> RMSE: 76.7547058320425
[LR: 0.0100, max_iter:    1000 lambda: 0.0004] --> RMSE: 76.75593762622988
[LR: 0.0100, max_iter:    1000 lambda: 0.0008] --> RMSE: 76.75842092485176
[LR: 0.0100, max_iter:    1000 lambda: 0.0010] --> RMSE: 76.75963549671361
[LR: 0.0100, max_iter:    1000 lambda: 0.0020] --> RMSE: 76.76624878919995
[LR: 0.0100, max_iter:    1000 lambda: 0.0050] --> RMSE: 76.78612646941548
[LR: 0.0100, max_iter:    1000 lambda: 0.0080] --> RMSE: 76.80717201865846
[LR: 0.0100, max_iter:    1000 lambda: 0.0100] --> RMSE: 76.82179821677435
[LR: 0.0100, max_iter:    1000 lambda: 0.0200] --> RMSE: 76.90008391258435
[LR: 0.0200, max_iter:    1000 lambda: 0.0000] --> RMSE: 76.64270304267816
[LR: 0.0200, max_iter:    1000 lambda: 0.0000] --> RMSE: 76.64284181253915
[LR: 0.0200, max_iter:    1000 lambda: 0.0001] --> RMSE: 76.64301111859605
[LR: 0.0200, max_iter:    1000 lambda: 0.0001] --> RMSE: 76.64312502637644
[LR: 0.0200, max_iter:    1000 lambda: 0.0001] --> RMSE: 76.64320144317277
[LR: 0.0200, max_iter:    1000 lambda: 0.0002] --> RMSE: 76.64382554522967
[LR: 0.0200, max_iter:    1000 lambda: 0.0004] --> RMSE: 76.64512993333872
[LR: 0.0200, max_iter:    1000 lambda: 0.0008] --> RMSE: 76.64752923819485
[LR: 0.0200, max_iter:    1000 lambda: 0.0010] --> RMSE: 76.64879297432498
[LR: 0.0200, max_iter:    1000 lambda: 0.0020] --> RMSE: 76.65525362884709
[LR: 0.0200, max_iter:    1000 lambda: 0.0050] --> RMSE: 76.67595296693474
[LR: 0.0200, max_iter:    1000 lambda: 0.0080] --> RMSE: 76.69869306030314
[LR: 0.0200, max_iter:    1000 lambda: 0.0100] --> RMSE: 76.71480600387147
[LR: 0.0200, max_iter:    1000 lambda: 0.0200] --> RMSE: 76.80417213106412
[LR: 0.0400, max_iter:    1000 lambda: 0.0000] --> RMSE: 76.60042979694046
[LR: 0.0400, max_iter:    1000 lambda: 0.0000] --> RMSE: 76.60050972103465
[LR: 0.0400, max_iter:    1000 lambda: 0.0001] --> RMSE: 76.60062705526406
[LR: 0.0400, max_iter:    1000 lambda: 0.0001] --> RMSE: 76.60071884336485
[LR: 0.0400, max_iter:    1000 lambda: 0.0001] --> RMSE: 76.60084520875772
[LR: 0.0400, max_iter:    1000 lambda: 0.0002] --> RMSE: 76.60141291687307
[LR: 0.0400, max_iter:    1000 lambda: 0.0004] --> RMSE: 76.60250156924461
[LR: 0.0400, max_iter:    1000 lambda: 0.0008] --> RMSE: 76.6048070819295
[LR: 0.0400, max_iter:    1000 lambda: 0.0010] --> RMSE: 76.6060077948953
[LR: 0.0400, max_iter:    1000 lambda: 0.0020] --> RMSE: 76.61223307416967
[LR: 0.0400, max_iter:    1000 lambda: 0.0050] --> RMSE: 76.633612623734
[LR: 0.0400, max_iter:    1000 lambda: 0.0080] --> RMSE: 76.65816546750206
[LR: 0.0400, max_iter:    1000 lambda: 0.0100] --> RMSE: 76.67588890548122
[LR: 0.0400, max_iter:    1000 lambda: 0.0200] --> RMSE: 76.77507240943213
[LR: 0.0600, max_iter:    1000 lambda: 0.0000] --> RMSE: 76.58956364562152
[LR: 0.0600, max_iter:    1000 lambda: 0.0000] --> RMSE: 76.58967237419932
[LR: 0.0600, max_iter:    1000 lambda: 0.0001] --> RMSE: 76.58977784486079
[LR: 0.0600, max_iter:    1000 lambda: 0.0001] --> RMSE: 76.58989399486501
[LR: 0.0600, max_iter:    1000 lambda: 0.0001] --> RMSE: 76.589989153674
[LR: 0.0600, max_iter:    1000 lambda: 0.0002] --> RMSE: 76.59053020757182
[LR: 0.0600, max_iter:    1000 lambda: 0.0004] --> RMSE: 76.59163886126292
[LR: 0.0600, max_iter:    1000 lambda: 0.0008] --> RMSE: 76.59390498906
[LR: 0.0600, max_iter:    1000 lambda: 0.0010] --> RMSE: 76.59509936997406
[LR: 0.0600, max_iter:    1000 lambda: 0.0020] --> RMSE: 76.60140238468821
[LR: 0.0600, max_iter:    1000 lambda: 0.0050] --> RMSE: 76.62362380797722
[LR: 0.0600, max_iter:    1000 lambda: 0.0080] --> RMSE: 76.64947398795317
[LR: 0.0600, max_iter:    1000 lambda: 0.0100] --> RMSE: 76.66815212756758
[LR: 0.0600, max_iter:    1000 lambda: 0.0200] --> RMSE: 76.77124532742633
[LR: 0.0800, max_iter:    1000 lambda: 0.0000] --> RMSE: 76.5848886757306
[LR: 0.0800, max_iter:    1000 lambda: 0.0000] --> RMSE: 76.5849953278736
[LR: 0.0800, max_iter:    1000 lambda: 0.0001] --> RMSE: 76.5850979934088
[LR: 0.0800, max_iter:    1000 lambda: 0.0001] --> RMSE: 76.5852010222175
[LR: 0.0800, max_iter:    1000 lambda: 0.0001] --> RMSE: 76.58529626431206
[LR: 0.0800, max_iter:    1000 lambda: 0.0002] --> RMSE: 76.58581089058126
[LR: 0.0800, max_iter:    1000 lambda: 0.0004] --> RMSE: 76.58687309343503
[LR: 0.0800, max_iter:    1000 lambda: 0.0008] --> RMSE: 76.58910929247827
[LR: 0.0800, max_iter:    1000 lambda: 0.0010] --> RMSE: 76.59028584540309
[LR: 0.0800, max_iter:    1000 lambda: 0.0020] --> RMSE: 76.5966216472663
[LR: 0.0800, max_iter:    1000 lambda: 0.0050] --> RMSE: 76.61944865563848
[LR: 0.0800, max_iter:    1000 lambda: 0.0080] --> RMSE: 76.6461920807168
[LR: 0.0800, max_iter:    1000 lambda: 0.0100] --> RMSE: 76.6654322316483
[LR: 0.0800, max_iter:    1000 lambda: 0.0200] --> RMSE: 76.7703626456224
[LR: 0.1000, max_iter:    1000 lambda: 0.0000] --> RMSE: 76.58273150092539
[LR: 0.1000, max_iter:    1000 lambda: 0.0000] --> RMSE: 76.58282598751069
[LR: 0.1000, max_iter:    1000 lambda: 0.0001] --> RMSE: 76.5829179529407
[LR: 0.1000, max_iter:    1000 lambda: 0.0001] --> RMSE: 76.58301327859468
[LR: 0.1000, max_iter:    1000 lambda: 0.0001] --> RMSE: 76.58311012898703
[LR: 0.1000, max_iter:    1000 lambda: 0.0002] --> RMSE: 76.58359173206114
[LR: 0.1000, max_iter:    1000 lambda: 0.0004] --> RMSE: 76.58459809061011
[LR: 0.1000, max_iter:    1000 lambda: 0.0008] --> RMSE: 76.58674488995271
[LR: 0.1000, max_iter:    1000 lambda: 0.0010] --> RMSE: 76.58788546220613
[LR: 0.1000, max_iter:    1000 lambda: 0.0020] --> RMSE: 76.59416343214279
[LR: 0.1000, max_iter:    1000 lambda: 0.0050] --> RMSE: 76.61736267522728
[LR: 0.1000, max_iter:    1000 lambda: 0.0080] --> RMSE: 76.64468215985403
[LR: 0.1000, max_iter:    1000 lambda: 0.0100] --> RMSE: 76.66427074379557
[LR: 0.1000, max_iter:    1000 lambda: 0.0200] --> RMSE: 76.77010987266851

Traceback (most recent call last):
  File "/Users/spandit/proj/CSCE633-ML/HW-1/Sourabh_Pandit_code.py", line 1070, in <module>
    main()
  File "/Users/spandit/proj/CSCE633-ML/HW-1/Sourabh_Pandit_code.py", line 826, in main
    grid_search_linreg()
  File "/Users/spandit/proj/CSCE633-ML/HW-1/Sourabh_Pandit_code.py", line 751, in grid_search_linreg
    linear_model.fit(X, y_train)
  File "/Users/spandit/proj/CSCE633-ML/HW-1/Sourabh_Pandit_code.py", line 274, in fit
    y_pred = self.predict(X_scaled)
  File "/Users/spandit/proj/CSCE633-ML/HW-1/Sourabh_Pandit_code.py", line 312, in predict
    X_scaled = self.scaler.transform(X)
  File "/opt/miniconda3/envs/csce633_py310_conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 319, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/csce633_py310_conda/lib/python3.10/site-packages/sklearn/preprocessing/_data.py", line 1062, in transform
    X = validate_data(
  File "/opt/miniconda3/envs/csce633_py310_conda/lib/python3.10/site-packages/sklearn/utils/validation.py", line 2944, in validate_data
    out = check_array(X, input_name="X", **check_params)
  File "/opt/miniconda3/envs/csce633_py310_conda/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1128, in check_array
    n_samples = _num_samples(array)
  File "/opt/miniconda3/envs/csce633_py310_conda/lib/python3.10/site-packages/sklearn/utils/validation.py", line 388, in _num_samples
    if _use_interchange_protocol(x):
  File "/opt/miniconda3/envs/csce633_py310_conda/lib/python3.10/site-packages/sklearn/utils/validation.py", line 325, in _use_interchange_protocol
    return not _is_pandas_df(X) and hasattr(X, "__dataframe__")
  File "/opt/miniconda3/envs/csce633_py310_conda/lib/python3.10/site-packages/sklearn/utils/validation.py", line 2349, in _is_pandas_df
    return isinstance(X, pd.DataFrame)
KeyboardInterrupt
